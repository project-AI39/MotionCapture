https://www.color-site.com/image_pickers
https://ironodata.info/extraction/irotoridori.php
http://www.aoki.ecei.tohoku.ac.jp/oc2020/3d/
https://mem-archive.com/2018/11/04/post-867/
https://mem-archive.com/2018/02/21/post-157/
https://mem-archive.com/2018/02/17/post-74/
https://blog.negativemind.com/2016/06/03/openmvs/
https://mem-archive.com/2018/03/04/post-259/

ストラクチャー・フロム・モーション (SfM) と多視点幾何学 (Multi-View Geometry) の違いは、以下のような点が挙げられます。
目的：SfMは、複数の画像から物体の三次元形状を推定することを目的とし、カメラの位置と姿勢を同時に推定します。一方、多視点幾何学は、複数の画像から物体の三次元形状を復元することを目的とし、カメラの位置と姿勢を推定するだけではありません。
基本的なアプローチ：SfMは、画像間の特徴点のマッチングに基づいて、カメラの位置と姿勢を推定します。一方、多視点幾何学は、複数の画像から物体の三次元形状を復元するために、画像間の対応関係を解析します。
精度：多視点幾何学は、SfMよりも精度が高く、複雑な形状の物体にも適用可能であるため、カメラの位置と姿勢を推定するための最も優れた手法の1つとされています。
以上が、SfMと多視点幾何学の違いについての概要です。

Pythonで多視点幾何学を実装する際には、以下のライブラリが利用できます。
OpenCV: OpenCVは、画像処理やコンピュータビジョンのためのライブラリであり、多視点幾何学の手法を実装するための関数が提供されています。具体的には、基本行列の推定、三角測量、バンドル調整などがサポートされています。
PyTorch3D: PyTorch3Dは、PyTorchをベースとした3Dコンピュータビジョンのためのライブラリであり、多視点幾何学の手法もサポートされています。PyTorch3Dを使うことで、高速なGPU演算によって多視点幾何学のアルゴリズムを実装することができます。
COLMAP: COLMAPは、Structure-from-Motionや多視点幾何学を含む3D再構成のためのオープンソースのソフトウェアです。PythonからCOLMAPを呼び出すことで、多視点幾何学のアルゴリズムを実装することができます。
これらのライブラリは、多視点幾何学の実装に必要な機能を提供しており、効率的かつ簡単に多視点幾何学の手法を実装することができます。

多視点幾何学（Multiple-View Geometry）の流れ
1.カメラキャリブレーション
複数のカメラから得られた画像を使って三次元復元をする場合、まず各カメラの内部パラメータ（カメラの焦点距離や歪み係数など）を求める必要があります。このプロセスをカメラキャリブレーションと呼びます。
2.特徴点の検出と対応付け
複数の画像から復元をする場合、それぞれの画像で同じ物体の部分を表す特徴点を検出し、対応付ける必要があります。これにより、画像間の関係を把握することができます。
3.基礎行列/本質行列の計算
カメラ行列を使って、各画像から対応点がどのように投影されているかを表すことができます。これを使って、対応点のエピポーラ制約を用いた基礎行列または本質行列を計算します。
4.三次元座標の計算
基礎行列/本質行列を使って、各画像上の対応点から、物体点の三次元座標を計算することができます。
5.復元結果の精度向上
復元結果の精度を向上するために、さまざまな手法があります。例えば、バンドル調整を行って、複数の画像間で一貫性のある復元結果を得ることができます。

以下は各パラメータの分解です
[[fx, 0, cx],
[0, fy, cy],
[0, 0, 1]]

fx：カメラの焦点距離をx方向に示すスケーリングファクター（ピクセル単位）
fy：カメラの焦点距離をy方向に示すスケーリングファクター（ピクセル単位）
cx：画像中心のx座標（ピクセル単位）
cy：画像中心のy座標（ピクセル単位）
rvecs_x：回転ベクトルのx方向成分
rvecs_y：回転ベクトルのy方向成分
rvecs_z：回転ベクトルのz方向成分
tvecs_x：並進ベクトルのx方向成分（ワールド座標系でのカメラ位置からの距離を示す）
tvecs_y：並進ベクトルのy方向成分（ワールド座標系でのカメラ位置からの距離を示す）
tvecs_z：並進ベクトルのz方向成分（ワールド座標系でのカメラ位置からの距離を示す）

opencv-python
https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html?highlight=triangulatepoints#cv2.triangulatePoints


エピポーラ幾何で8つのカメラを使うには、以下の手順で行います。

8つのカメラで同じ物体を撮影する。
各カメラの画像から、対応点を検出する。
各対応点から、エピポーラ線を計算する。
エピポーラ線の交点を計算する。
交点から、3次元座標を計算する。
具体的には、以下の手法が適用されます。

カメラの位置と向きが不明な場合
カメラの位置と向きが不明な場合は、以下の手順で行います。

各エピポーラ線の交点から、カメラの位置と向きを推定する。
推定されたカメラの位置と向きから、エピポーラ線の交点を計算する。
交点から、3次元座標を計算する。
カメラの位置と向きが既知の場合
カメラの位置と向きが既知の場合は、以下の手順で行います。

各エピポーラ線の交点を計算する。
交点から、3次元座標を計算する。
なお、8つのカメラを使用する場合、カメラの位置と向きを推定することが一般的です。

これは、エピポーラ線の交点が複数存在する可能性があるため、カメラの位置と向きを推定することで、交点をより特定しやすくなるためです。

また、カメラの位置と向きを推定するには、以下の手法が適用されます。

最尤推定
最尤推定は、最も尤もらしいカメラの位置と向きを推定する手法です。

最小二乗法
最小二乗法は、エピポーラ線の交点の誤差を最小化するカメラの位置と向きを推定する手法です。

人工知能
人工知能を用いて、カメラの位置と向きを推定する手法です。

なお、エピポーラ幾何は、8つのカメラを使用する場合でも、カメラの誤差や対応点の誤差によって、3次元座標の復元精度が低下する可能性があります。

そのため、カメラの誤差や対応点の誤差を補正するための手法が適用されることもあります。

具体的には、以下の手法が適用されます。

カメラの誤差補正
カメラの誤差補正は、カメラの誤差を補正する手法です。

対応点の誤差補正
対応点の誤差補正は、対応点の誤差を補正する手法です。

ランダムフォレスト
ランダムフォレストを用いて、カメラの誤差や対応点の誤差を補正する手法です。
https://whitewell.sakura.ne.jp/OpenCV/Notebook/epipolar_geometry.html
https://gist.github.com/JotaroS/64fd3bb567c8b833c90336c58eb234a5
https://academic-accelerator.com/Manuscript-Generator/jp/Epipolar-Geometry
https://qiita.com/ykoga/items/14300e8cdf5aa7bd8d31